---
# Source: telegraf-ds/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: telegraf-ds
  namespace: loki
  labels:
    helm.sh/chart: telegraf-ds-1.1.17
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: telegraf-ds
    app.kubernetes.io/instance: telegraf-ds
---
# Source: telegraf-ds/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: telegraf-ds
  namespace: loki
  labels:
    helm.sh/chart: telegraf-ds-1.1.17
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: telegraf-ds
    app.kubernetes.io/instance: telegraf-ds
data:
  telegraf.conf: |+
    [global_tags]
      instance = "${HOSTIP}"
      nodename = "${HOSTNAME}"
      projectname = "${PROJECTNAME}"
    [agent]
      collection_jitter = "0s"
      debug = false
      flush_interval = "10s"
      flush_jitter = "0s"
      hostname = "$HOSTNAME"
      interval = "10s"
      logfile = ""
      metric_batch_size = 1000
      metric_buffer_limit = 10000
      omit_hostname = false
      precision = ""
      quiet = false
      round_interval = true
    
    
    [[outputs.opentelemetry]]
      service_address = "otel-collector:4317"
      timeout = "5s"
    
    
    [[inputs.diskio]]
    [[inputs.kernel]]
    [[inputs.mem]]
    [[inputs.net]]
    [[inputs.processes]]
    [[inputs.swap]]
    [[inputs.system]]
    [[inputs.cpu]]
      collect_cpu_time = false
      percpu = true
      report_active = false
      totalcpu = true
    [[inputs.disk]]
      ignore_fs = [
        "tmpfs",
        "devtmpfs",
        "devfs",
        "iso9660",
        "overlay",
        "aufs",
        "squashfs"
      ]
    [[inputs.kubernetes]]
      bearer_token = "/var/run/secrets/kubernetes.io/serviceaccount/token"
      insecure_skip_verify = true
      url = "https://$HOSTIP:10250"
    
    [[inputs.docker]]
    endpoint = "unix:///run/k3s/containerd/containerd.sock"
---
# Source: telegraf-ds/templates/role.yaml
# kubernetes_plugin: Give access to stats endpoints
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: influx-stats-viewer
  labels:
    helm.sh/chart: telegraf-ds-1.1.17
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: telegraf-ds
    app.kubernetes.io/instance: telegraf-ds
    rbac.authorization.k8s.io/aggregate-view-telegraf-stats: "true"
rules:
  - apiGroups: ["metrics.k8s.io"]
    resources: ["pods"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["nodes/proxy", "nodes/stats"]
    verbs: ["get", "list", "watch"]
---
# Source: telegraf-ds/templates/role.yaml
# Define global role with the default system:aggregate-to-view cluster role and the two rules we just created
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: influx:telegraf
aggregationRule:
  clusterRoleSelectors:
    - matchLabels:
        rbac.authorization.k8s.io/aggregate-view-telegraf-stats: "true"
    - matchLabels:
        rbac.authorization.k8s.io/aggregate-to-view: "true"
rules: [] # Rules are automatically filled in by the controller manager.
---
# Source: telegraf-ds/templates/rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: influx-telegraf-viewer
  labels:
    helm.sh/chart: telegraf-ds-1.1.17
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: telegraf-ds
    app.kubernetes.io/instance: telegraf-ds
subjects:
  - kind: ServiceAccount
    name: telegraf-ds
    namespace: loki
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: influx:telegraf
---
# Source: telegraf-ds/templates/daemonset.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: telegraf-ds
  namespace: loki
  labels:
    helm.sh/chart: telegraf-ds-1.1.17
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: telegraf-ds
    app.kubernetes.io/instance: telegraf-ds
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: telegraf-ds
      app.kubernetes.io/instance: telegraf-ds
  template:
    metadata:
      labels:
        app.kubernetes.io/name: telegraf-ds
        app.kubernetes.io/instance: telegraf-ds
      annotations:
        # Include a hash of the configmap in the pod template
        # This means that if the configmap changes, the deployment will be rolled
        checksum/config: 6c6ccc2ec6edb970ae800f2f341657998842482c408b3a88641991aa8f670d1a
    spec:
      serviceAccountName: telegraf-ds
      containers:
      - name: telegraf-ds
        image:  "docker.io/library/telegraf:1.28"
        imagePullPolicy: "IfNotPresent"
        resources:
          limits:
            cpu: 1
            memory: 2Gi
          requests:
            cpu: 0.1
            memory: 256Mi
        env:
        - name: HOSTIP
          valueFrom:
            fieldRef:
              fieldPath: status.hostIP
        - name: PROJECTNAME
          value: sc-dazhou-sentry 
        - name: HOSTNAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        - name: HOSTIP
          valueFrom:
            fieldRef:
              fieldPath: status.hostIP
        - name: HOST_PROC
          value: /hostfs/proc
        - name: HOST_SYS
          value: /hostfs/sys
        - name: HOST_MOUNT_PREFIX
          value: /hostfs
        volumeMounts:
        - name: varrunutmpro
          mountPath: /var/run/utmp
          readOnly: true
        - name: hostfsro
          mountPath: /hostfs
          readOnly: true
        - name: docker-socket
          mountPath: /run/k3s/containerd/containerd.sock
        - name: config
          mountPath: /etc/telegraf
      volumes:
      - name: hostfsro
        hostPath:
          path: /
      - name: docker-socket
        hostPath:
          path: /run/k3s/containerd/containerd.sock
          type: Socket
      - name: varrunutmpro
        hostPath:
          path: /var/run/utmp
      - name: config
        configMap:
          name:  telegraf-ds
      hostNetwork: false

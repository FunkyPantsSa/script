---
# Source: netdata/templates/psp.yaml
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: netata-netdata-psp
  labels:
    heritage: Helm
    release: netata
    chart: netdata-3.7.30
spec:
  allowPrivilegeEscalation: true
  allowedCapabilities:
    - SYS_PTRACE
    - SYS_ADMIN
  fsGroup:
    rule: RunAsAny
  hostIPC: true
  hostNetwork: true
  hostPID: true
  hostPorts:
  - max: 65535
    min: 0
  privileged: true
  runAsUser:
    rule: RunAsAny
  seLinux:
    rule: RunAsAny
  supplementalGroups:
    rule: RunAsAny
  volumes:
  - '*'
---
# Source: netdata/templates/serviceaccount.yaml
kind: ServiceAccount
apiVersion: v1
metadata:
  labels:
    app: netdata
    chart: netdata-3.7.30
    release: netata
    heritage: Helm
  name: netdata
---
# Source: netdata/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: netdata-conf-parent
  labels:
    app: netdata
    chart: netdata-3.7.30
    release: netata
    heritage: Helm
data:
  health: |
      SEND_EMAIL="NO"
      SEND_SLACK="YES"
      SLACK_WEBHOOK_URL=""
      DEFAULT_RECIPIENT_SLACK=""
      role_recipients_slack[sysadmin]="${DEFAULT_RECIPIENT_SLACK}"
      role_recipients_slack[domainadmin]="${DEFAULT_RECIPIENT_SLACK}"
      role_recipients_slack[dba]="${DEFAULT_RECIPIENT_SLACK}"
      role_recipients_slack[webmaster]="${DEFAULT_RECIPIENT_SLACK}"
      role_recipients_slack[proxyadmin]="${DEFAULT_RECIPIENT_SLACK}"
      role_recipients_slack[sitemgr]="${DEFAULT_RECIPIENT_SLACK}"
  netdata: |
      [global]
        memory mode = dbengine
    
      [plugins]
        cgroups = yes
        tc = no
        enable running new plugins = no
        check for new plugins every = 72000
        python.d = no
        charts.d = no
        go.d = no
        node.d = no
        apps = no
        proc = no
        idlejitter = no
        diskspace = no
    
      [db]
          mode = dbengine
          # per second data collection
          update every = 1
          # enables Tier 1 and Tier 2, Tier 0 is always enabled in dbengine mode
          storage tiers = 3
          # Tier 0, per second data for a week
          dbengine multihost disk space MB = 5000
          # Tier 1, per minute data for a month
          dbengine tier 1 multihost disk space MB = 330
          # Tier 2, per hour data for a year
          dbengine tier 2 multihost disk space MB = 67
  stream: |
      [11111111-2222-3333-4444-555555555555]
        enabled = yes
        history = 3600
        default memory mode = dbengine
        health enabled by default = auto
        allow from = *
---
# Source: netdata/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: netdata-conf-child
  labels:
    app: netdata
    chart: netdata-3.7.30
    release: netata
    heritage: Helm
data:
  go.d: |
      modules:
        pulsar: no
        prometheus: yes
  kubelet: |
      update_every: 1
      autodetection_retry: 0
      jobs:
        - url: http://127.0.0.1:10255/metrics
        - url: https://localhost:10250/metrics
          tls_skip_verify: yes
  kubeproxy: |
      update_every: 1
      autodetection_retry: 0
      jobs:
        - url: http://127.0.0.1:10249/metrics
  netdata: |
      [global]
        memory mode = ram
      [health]
        enabled = no
      [ml]
        enabled = no
  stream: |
      [stream]
        enabled = yes
        destination = netdata:19999
        api key = 11111111-2222-3333-4444-555555555555
        timeout seconds = 60
        buffer size bytes = 1048576
        reconnect delay seconds = 5
        initial clock resync iterations = 60
---
# Source: netdata/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: netdata-conf-k8s-state
  labels:
    app: netdata
    chart: netdata-3.7.30
    release: netata
    heritage: Helm
data:
  postgres: |
      jobs:
        - name: remote
          dsn: 'postgres://root:root@123456@pgsql.middleware:5432/postgres'
  redis: |
      jobs:
        - name: remote
          address: 'redis://:redis123@redis.middleware:6379'
  fping: |
      fping="/usr/local/bin/fping"
      hosts="114.114.114.114"
      update_every=1
      ping_every=500
      fping_opts="-R -b 56 -i 1 -r 0 -t 5000"
  go.d: |
      default_run: no
      modules:
        k8s_state: yes
        redis: yes
        postgres: yes
  go.d-k8s_state: |
      jobs:
        - name: k8s_state
          update_every: 1
  netdata: |
      [global]
        memory mode = ram
      [health]
        enabled = no
      [ml]
        enabled = no
      [plugins]
        timex = no
        checks = no
        idlejitter = no
        tc = no
        diskspace = no
        proc = no
        cgroups = no
        enable running new plugins = no
        slabinfo = no
        perf = no
        go.d = yes
        ioping = no
        ebpf = no
        charts.d = no
        apps = no
        python.d = no
        fping = yes
  stream: |
      [stream]
        enabled = yes
        destination = netdata:19999
        api key = 11111111-2222-3333-4444-555555555555
        timeout seconds = 60
        buffer size bytes = 1048576
        reconnect delay seconds = 5
        initial clock resync iterations = 60
---
# Source: netdata/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: netdata-child-sd-config-map
  labels:
    app: netdata
    chart: netdata-3.7.30
    release: netata
    heritage: Helm
data:
  config.yml: |
    name: kubernetes
    discovery:
      k8s:
        - tags: unknown
          role: pod
          local_mode: true
    tag:
      - name: "Control-Plane"
        selector: unknown
        tags: -unknown control_plane
        match:
          - tags: kube_scheduler
            expr: '{{ glob .Image "k8s.gcr.io/kube-scheduler:*" }}'
          - tags: kube_controller_manager
            expr: '{{ glob .Image "k8s.gcr.io/kube-controller-manager:*" }}'
      - name: "Applications"
        selector: unknown
        tags: -unknown applications
        match:
          - tags: activemq
            expr: '{{ and (eq .Port "8161") (glob .Image "**/activemq*") }}'
          - tags: apache
            expr: '{{ and (eq .Port "80" "8080") (glob .Image "httpd*" "**/httpd*") }}'
          - tags: bind
            expr: '{{ and (eq .Port "8653") (glob .Image "**/bind*") }}'
          - tags: cockroachdb
            expr: '{{ and (eq .Port "8080") (glob .Image "**/cockroach*") }}'
          - tags: consul
            expr: '{{ and (eq .Port "8500") (glob .Image "consul*" "**/consul*") }}'
          - tags: coredns
            expr: '{{ and (eq .Port "9153") (glob .Image "**/coredns*") }}'
          - tags: elasticsearch
            expr: '{{ and (eq .Port "9200") (glob .Image "elasticsearch:*" "**/elasticsearch:*") }}'
          - tags: fluentd
            expr: '{{ and (eq .Port "24220") (glob .Image "fluentd*" "**/fluentd*") }}'
          - tags: freeradius
            expr: '{{ and (eq .Port "18121") (glob .Image "**/freeradius*") }}'
          - tags: hdfs
            expr: '{{ and (eq .Port "50070") (glob .Image "**/hdfs*") }}'
          - tags: lighttpd
            expr: '{{ and (eq .Port "80" "8080") (glob .Image "**/lighttpd*") }}'
          - tags: lighttpd2
            expr: '{{ and (eq .Port "80" "8080") (glob .Image "**/lighttpd2*") }}'
          - tags: logstash
            expr: '{{ and (eq .Port "9600") (glob .Image "logstash*" "**/logstash*") }}'
          - tags: mysql
            expr: '{{ and (eq .Port "3306") (glob .Image "mysql*" "**/mysql*" "mariadb*" "**/mariadb*") }}'
          - tags: nginx
            expr: '{{ and (eq .Port "80" "8080") (glob .Image "nginx*" "**/nginx*") }}'
          - tags: openvpn
            expr: '{{ and (eq .Port "7505") (glob .Image "**/openvpn") }}'
          - tags: phpfpm
            expr: '{{ and (eq .Port "80" "8080") (glob .Image "**/phpfpm*" "**/php-fpm*") }}'
          - tags: rabbitmq
            expr: '{{ and (eq .Port "15672") (glob .Image "rabbitmq*" "**/rabbitmq*") }}'
          - tags: solr
            expr: '{{ and (eq .Port "8983") (glob .Image "solr*" "**/solr*") }}'
          - tags: tengine
            expr: '{{ and (eq .Port "80" "8080") (glob .Image "**/tengine*") }}'
          - tags: unbound
            expr: '{{ and (eq .Port "8953") (glob .Image "**/unbound*") }}'
          - tags: vernemq
            expr: '{{ and (eq .Port "8888") (glob .Image "**/vernemq*") }}'
          - tags: zookeeper
            expr: '{{ and (eq .Port "2181") (glob .Image "zookeeper*" "**/zookeeper*") }}'
      - name: "Prometheus Generic Applications"
        selector: unknown
        tags: -unknown prometheus_generic
        match:
          - tags: prometheus_generic
            expr: |
              {{ $scrapeOK := eq (get .Annotations "prometheus.io/scrape") "true" -}}
              {{ $portOK := eq (default .Port (get .Annotations "prometheus.io/port")) .Port -}}
              {{ $imageOK := not (glob .Image "netdata/netdata*" "**pulsar*" "**telegraf*") -}}
              {{ and $scrapeOK $portOK $imageOK }}
    build:
      - name: "Control-Plane"
        selector: '!unknown control_plane'
        tags: file
        apply:
          - selector: kube_scheduler
            template: |
              - module: prometheus
                name: prometheus-{{.TUID}}
                url: http://{{.PodIP}}:{{default "10251" .Port}}/metrics
                app: '{{.ContName}}'
                update_every: 10
                max_time_series: 1000
          - selector: kube_controller_manager
            template: |
              - module: prometheus
                name: prometheus-{{.TUID}}
                url: http://{{.PodIP}}:{{default "10252" .Port}}/metrics
                app: '{{.ContName}}'
                update_every: 10
                max_time_series: 2000
      - name: "Prometheus Generic Applications"
        selector: '!unknown prometheus_generic'
        tags: file
        apply:
          - selector: prometheus_generic
            template: |
              {{ $path := default "/metrics" (get .Annotations "prometheus.io/path") -}}
              - module: prometheus
                name: prometheus-{{.TUID}}
                url: http://{{.Address}}{{$path}}
                app: '{{.ContName}}'
                update_every: 10
                max_time_series: 4000
      - name: "Applications"
        selector: '!unknown applications'
        tags: file
        apply:
          - selector: activemq
            template: |
              - module: activemq
                name: activemq-{{.TUID}}
                url: http://{{.Address}}
          - selector: apache
            template: |
              - module: apache
                name: apache-{{.TUID}}
                url: http://{{.Address}}/server-status?auto
          - selector: bind
            template: |
              - module: bind
                name: bind-{{.TUID}}
                url: http://{{.Address}}/json/v1
          - selector: cockroachdb
            template: |
              - module: cockroachdb
                name: cockroachdb-{{.TUID}}
                url: http://{{.Address}}/_status/vars
          - selector: consul
            template: |
              - module: consul
                name: consul-{{.TUID}}
                url: http://{{.Address}}
          - selector: coredns
            template: |
              - module: coredns
                name: coredns-{{.TUID}}
                url: http://{{.Address}}/metrics
          - selector: elasticsearch
            template: |
              - module: elasticsearch
                name: elasticsearch-{{.TUID}}
                url: http://{{.Address}}
          - selector: fluentd
            template: |
              - module: fluentd
                name: fluentd-{{.TUID}}
                url: http://{{.Address}}
          - selector: freeradius
            template: |
              - module: freeradius
                name: freeradius-{{.TUID}}
                address: {{.PodIP}}
                port: {{.Port}}
          - selector: hdfs
            template: |
              - module: hdfs
                name: hdfs-{{.TUID}}
                url: http://{{.Address}}/jmx
          - selector: lighttpd
            template: |
              - module: lighttpd
                name: lighttpd-{{.TUID}}
                url: http://{{.Address}}/server-status?auto
          - selector: lighttpd2
            template: |
              - module: lighttpd2
                name: lighttpd2-{{.TUID}}
                url: http://{{.Address}}/server-status?format=plain
          - selector: logstash
            template: |
              - module: logstash
                name: logstash-{{.TUID}}
                url: http://{{.Address}}
          - selector: mysql
            template: |
              - module: mysql
                name: mysql-{{.TUID}}
                dsn: 'netdata@tcp({{.Address}})/'
          - selector: nginx
            template: |
              - module: nginx
                name: nginx-{{.TUID}}
                url: http://{{.Address}}/stub_status
          - selector: openvpn
            template: |
              - module: openvpn
                name: openvpn-{{.TUID}}
                address: {{.Address}}
          - selector: phpfpm
            template: |
              - module: phpfpm
                name: phpfpm-{{.TUID}}
                url: http://{{.Address}}/status?full&json
          - selector: rabbitmq
            template: |
              - module: rabbitmq
                name: rabbitmq-{{.TUID}}
                url: http://{{.Address}}
          - selector: solr
            template: |
              - module: solr
                name: solr-{{.TUID}}
                url: http://{{.Address}}
          - selector: tengine
            template: |
              - module: tengine
                name: tengine-{{.TUID}}
                url: http://{{.Address}}/us
          - selector: unbound
            template: |
              - module: unbound
                name: unbound-{{.TUID}}
                address: {{.Address}}
                use_tls: false
          - selector: vernemq
            template: |
              - module: vernemq
                name: vernemq-{{.TUID}}
                url: http://{{.Address}}/metrics
          - selector: zookeeper
            template: |
              - module: zookeeper
                name: zookeeper-{{.TUID}}
                address: {{.Address}}
    export:
      file:
        - selector: file
          filename: "/export/go.d.yml"
---
# Source: netdata/templates/persistentvolumeclaim.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: netdata-parent-database
  labels:
    app: netdata
    chart: netdata-3.7.30
    release: netata
    heritage: Helm
    role: parent
spec:
  accessModes: [ "ReadWriteOnce" ]
  resources:
    requests:
      storage: 2Gi
---
# Source: netdata/templates/persistentvolumeclaim.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: netdata-parent-alarms
  labels:
    app: netdata
    chart: netdata-3.7.30
    release: netata
    heritage: Helm
    role: parent
spec:
  accessModes: [ "ReadWriteOnce" ]
  resources:
    requests:
      storage: 1Gi
---
# Source: netdata/templates/persistentvolumeclaim.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: netdata-k8s-state-varlib
  labels:
    app: netdata
    chart: netdata-3.7.30
    release: netata
    heritage: Helm
    role: k8sState
spec:
  accessModes: [ "ReadWriteOnce" ]
  resources:
    requests:
      storage: 1Gi
---
# Source: netdata/templates/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: netata-netdata
  labels:
    app: netdata
    chart: netdata-3.7.30
    release: netata
    heritage: Helm
rules:
  - apiGroups: [""]
    resources:
      - "pods"           # used by sd, go.d/k8s_state, netdata (cgroup-name.sh, get-kubernetes-labels.sh)
      - "services"       # used by sd
      - "configmaps"     # used by sd
      - "secrets"        # used by sd
      - "nodes"          # used by go.d/k8s_state
      - "nodes/metrics"  # used by go.d/k8s_state when querying Kubelet HTTPS endpoint
    verbs:
      - "get"
      - "list"
      - "watch"
  - apiGroups: [""]
    resources:
      - "namespaces"  # used by go.d/k8s_state, netdata (cgroup-name.sh, get-kubernetes-labels.sh)
    verbs:
      - "get"
---
# Source: netdata/templates/psp-clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: netata-netdata-psp
  labels:
    app: netdata
    chart: netdata-3.7.30
    release: netata
    heritage: Helm
rules:
- apiGroups: ['policy']
  resources: ['podsecuritypolicies']
  verbs:     ['use']
  resourceNames:
  - netata-netdata-psp
---
# Source: netdata/templates/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: netata-netdata
  labels:
    app: netdata
    chart: netdata-3.7.30
    release: netata
    heritage: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: netata-netdata
subjects:
- kind: ServiceAccount
  name: netdata
  namespace: default
---
# Source: netdata/templates/psp-clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: netata-netdata-psp
  labels:
    app: netdata
    chart: netdata-3.7.30
    release: netata
    heritage: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: netata-netdata-psp
subjects:
- kind: ServiceAccount
  name: netdata
  namespace: default
---
# Source: netdata/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: netdata
  labels:
    app: netdata
    chart: netdata-3.7.30
    release: netata
    heritage: Helm
    role: parent
  annotations:
spec:
  type: NodePort
  ports:
    - port: 19999
      nodePort: 29999
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app: netdata
    release: netata
    role: parent
---
# Source: netdata/templates/daemonset.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: netdata-child
  labels:
    app: netdata
    chart: netdata-3.7.30
    release: netata
    heritage: Helm
    role: child
spec:
  selector:
    matchLabels:
      app: netdata
      release: netata
      role: child
  template:
    metadata:
      annotations:
        container.apparmor.security.beta.kubernetes.io/netdata: unconfined
        checksum/config: 4c1637c307182c04372d0d91942473153cb2fa3cf76e2807266d720b82a6368d
      labels:
        app: netdata
        release: netata
        role: child
    spec:
      serviceAccountName: netdata
      restartPolicy: Always
      hostPID: true
      hostIPC: true
      hostNetwork: true
      initContainers:
        - name: init-persistence
          image: "alpine:latest"
          resources:
            requests:
              cpu: 10m
          imagePullPolicy: IfNotPresent
          volumeMounts:
            - name: persistencevarlibdir
              mountPath: "/persistencevarlibdir"
          command:
            - "/bin/sh"
          args:
            - "-c"
            - '
            chmod 777 /persistencevarlibdir;
            '
      containers:
        - name: netdata
          image: "netdata/netdata:v1.36.1"
          imagePullPolicy: IfNotPresent
          env:
            - name: MY_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: MY_NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: MY_POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: NETDATA_LISTENER_PORT
              value: '19999'
            - name: NETDATA_PLUGINS_GOD_WATCH_PATH
              value: "/etc/netdata/go.d/sd/go.d.yml"
          ports:
            - name: http
              containerPort: 19999
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /api/v1/info
              port: http
            failureThreshold: 3
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 1
          readinessProbe:
            httpGet:
              path: /api/v1/info
              port: http
            failureThreshold: 3
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 1
          volumeMounts:
            - name: proc
              readOnly: true
              mountPath: /host/proc
            - name: run
              mountPath: /var/run/docker.sock
            - name: sys
              mountPath: /host/sys
            - name: os-release
              mountPath: /host/etc/os-release
            - name: config
              mountPath: /etc/netdata/go.d.conf
              subPath: go.d
            - name: config
              mountPath: /etc/netdata/go.d/k8s_kubelet.conf
              subPath: kubelet
            - name: config
              mountPath: /etc/netdata/go.d/k8s_kubeproxy.conf
              subPath: kubeproxy
            - name: config
              mountPath: /etc/netdata/netdata.conf
              subPath: netdata
            - name: config
              mountPath: /etc/netdata/stream.conf
              subPath: stream
            - name: persistencevarlibdir
              mountPath: /var/lib/netdata
            - name: sd-shared
              mountPath: "/etc/netdata/go.d/sd/"
          securityContext:
            capabilities:
              add:
                - SYS_PTRACE
                - SYS_ADMIN
          resources:
            {}
        - name: sd
          image: "netdata/agent-sd:v0.2.6"
          imagePullPolicy: IfNotPresent
          volumeMounts:
            - name: sd-shared
              mountPath: "/export/"
          resources:
            limits:
              cpu: 50m
              memory: 150Mi
            requests:
              cpu: 50m
              memory: 100Mi
          env:
            - name: NETDATA_SD_CONFIG_MAP
              value: "netdata-child-sd-config-map:config.yml"
            - name: MY_POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: MY_NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
      tolerations:
        - effect: NoSchedule
          operator: Exists
      terminationGracePeriodSeconds: 30
      volumes:
        - name: proc
          hostPath:
            path: /proc
        - name: run
          hostPath:
            path: /var/run/docker.sock
        - name: sys
          hostPath:
            path: /sys
        - name: os-release
          hostPath:
            path: /etc/os-release
        - name: config
          configMap:
            name: netdata-conf-child
        - name: persistencevarlibdir
          hostPath:
            path: /var/lib/netdata-k8s-child/var/lib/netdata
            type: DirectoryOrCreate
        - name: sd-shared
          emptyDir: { }
      dnsPolicy: ClusterFirstWithHostNet
---
# Source: netdata/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: netdata-parent
  labels:
    app: netdata
    chart: netdata-3.7.30
    release: netata
    heritage: Helm
    role: parent
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: netdata
      release: netata
      role: parent
  template:
    metadata:
      labels:
        app: netdata
        release: netata
        role: parent
      annotations:
        checksum/config: 4c1637c307182c04372d0d91942473153cb2fa3cf76e2807266d720b82a6368d
    spec:
      securityContext:
        fsGroup: 201
      serviceAccountName: netdata
      initContainers:
      containers:
        - name: netdata
          image: "netdata/netdata:v1.36.1"
          imagePullPolicy: IfNotPresent
          env:
            - name: MY_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: MY_POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: NETDATA_LISTENER_PORT
              value: '19999'
          ports:
            - name: http
              containerPort: 19999
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /api/v1/info
              port: http
            failureThreshold: 3
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 1
          readinessProbe:
            httpGet:
              path: /api/v1/info
              port: http
            failureThreshold: 3
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 1
          volumeMounts:
            - name: os-release
              mountPath: /host/etc/os-release
            - name: config
              mountPath: /etc/netdata/health_alarm_notify.conf
              subPath: health
            - name: config
              mountPath: /etc/netdata/netdata.conf
              subPath: netdata
            - name: config
              mountPath: /etc/netdata/stream.conf
              subPath: stream
            - name: database
              mountPath: /var/cache/netdata
            - name: alarms
              mountPath: /var/lib/netdata
          resources:
            {}
      nodeSelector:
        node-role.kubernetes.io/master: "true"
      terminationGracePeriodSeconds: 300
      volumes:
        - name: os-release
          hostPath:
            path: /etc/os-release
        - name: config
          configMap:
            name: netdata-conf-parent
        - name: database
          hostPath:
            path: /netdata/database
            type: DirectoryOrCreate
            #persistentVolumeClaim:
              #claimName: netdata-parent-database
        - name: alarms
          hostPath:
            path: /netdata/alarms
            type: DirectoryOrCreate
           #persistentVolumeClaim:
             #claimName: netdata-parent-alarms
      dnsPolicy: Default
---
# Source: netdata/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: netdata-k8s-state
  labels:
    app: netdata
    chart: netdata-3.7.30
    release: netata
    heritage: Helm
    role: k8sState
spec:
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: netdata
      release: netata
      role: k8sState
  template:
    metadata:
      annotations:
        container.apparmor.security.beta.kubernetes.io/netdata: unconfined
        checksum/config: 4c1637c307182c04372d0d91942473153cb2fa3cf76e2807266d720b82a6368d
      labels:
        app: netdata
        release: netata
        role: k8sState
    spec:
      securityContext:
        fsGroup: 201
      serviceAccountName: netdata
      restartPolicy: Always
      initContainers:
      containers:
        - name: netdata
          image: "netdata/netdata:v1.36.1"
          imagePullPolicy: IfNotPresent
          env:
            - name: NETDATA_LISTENER_PORT
              value: '19999'
          ports:
            - name: http
              containerPort: 19999
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /api/v1/info
              port: http
            failureThreshold: 3
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 1
          readinessProbe:
            httpGet:
              path: /api/v1/info
              port: http
            failureThreshold: 3
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 1
          volumeMounts:
            - name: os-release
              mountPath: /host/etc/os-release
            - name: config
              mountPath: /etc/netdata/fping.conf
              subPath: fping
            - name: config
              mountPath: /etc/netdata/go.d/redis.conf
              subPath: redis 
            - name: config
              mountPath: /etc/netdata/go.d/postgres.conf
              subPath: postgres
            - name: config
              mountPath: /etc/netdata/go.d.conf
              subPath: go.d
            - name: config
              mountPath: /etc/netdata/go.d/k8s_state.conf
              subPath: go.d-k8s_state
            - name: config
              mountPath: /etc/netdata/netdata.conf
              subPath: netdata
            - name: config
              mountPath: /etc/netdata/stream.conf
              subPath: stream
            - name: varlib
              mountPath: /var/lib/netdata
          resources:
            {}
      tolerations:
        - effect: NoSchedule
          operator: Exists
      terminationGracePeriodSeconds: 30
      volumes:
        - name: os-release
          hostPath:
            path: /etc/os-release
        - name: config
          configMap:
            name: netdata-conf-k8s-state
        - name: varlib
          persistentVolumeClaim:
            claimName: netdata-k8s-state-varlib
      dnsPolicy: ClusterFirstWithHostNet
---
# Source: netdata/templates/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: netdata
  labels:
    app: netdata
    chart: netdata-3.7.30
    release: netata
    heritage: Helm
  annotations:
    kubernetes.io/ingress.class: nginx
    kubernetes.io/tls-acme: "true"
spec:
  rules:
    - host: netdata.k8s.local
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: netdata
                port:
                  name: http
